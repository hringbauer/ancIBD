{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create test data to check implementation of HMM\n",
    "Creates data under the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-a-16-54.o2.rc.hms.harvard.edu\n",
      "HSM O2 Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/hapBLOCK\n",
      "CPU Count: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import allel\n",
    "import itertools as it\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Array of Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_normal_all_freqs(l=5000, mean=0.5, std=0.1):\n",
    "    \"\"\"Draw Normally distributed allele frequencies\"\"\"\n",
    "    p = np.random.normal(size=l, loc=mean, scale=std)\n",
    "    return p\n",
    "\n",
    "def draw_haplotype(p):\n",
    "    \"\"\"Draw binomal haplotype from allele frequency p.\n",
    "    For each locus draw one genotype\n",
    "    Assumes Hardy Weinbgerg.\"\"\"\n",
    "    l = len(p)\n",
    "    s = np.random.random(size=l)<p\n",
    "    return s\n",
    "\n",
    "def create_hap_ll(h):\n",
    "    \"\"\"Create vector of haplotype likelihood.\n",
    "    Without error. \n",
    "    h: Haplotype vector [l] consisting of 0/1\"\"\"\n",
    "    l = np.zeros((len(h),2), dtype=\"bool\")\n",
    "    idx_der = (h==1)\n",
    "    l[idx_der, 1] = 1\n",
    "    l[~idx_der, 0] = 1\n",
    "    return l\n",
    "    \n",
    "def copy_in_block(h_s, h_t, loc=[10,20]):\n",
    "    \"\"\"Copy in Haplotype block by copying segment.\n",
    "    h_s: The source haplotype\n",
    "    h_t: The target haplotype\n",
    "    loc: Location of haplotype to copy over\"\"\"\n",
    "    h_t[loc[0]:loc[1]]=h_s[loc[0]:loc[1]]\n",
    "    return h_t\n",
    "\n",
    "def create_ibd_haplos(l=10000, loc=[2000,4000], mean=0.5, std=0.1):\n",
    "    \"\"\"Create haplotype likelihoods with IBD copying.\n",
    "    Draw allele frequencies, create HW haplotypes, copy in haplotype\n",
    "    and create likelihoods.\n",
    "    Return p [l] and haplotypelikelihoods [4,l,2]\"\"\"\n",
    "    p = draw_normal_all_freqs(l=l, mean=mean, std=std)\n",
    "    hts = [draw_haplotype(p) for _ in range(4)]\n",
    "    hts[0] = copy_in_block(h_s=hts[2], h_t=hts[0], loc=loc)\n",
    "    htsl = np.array([create_hap_ll(h) for h in hts])\n",
    "    return p, htsl\n",
    "\n",
    "def save_haplo_ll(hts, p=[], folder=\"./output/simulated/undermodel/\",\n",
    "                  delimiter='\\t'):\n",
    "    \"\"\"Save Haplotype Likelihoods in standardized format.\"\"\"\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    savepath = os.path.join(folder,\"haplo_ll.tsv\")\n",
    "    np.savetxt(savepath, hts, delimiter=delimiter)\n",
    "    print(f\"Saved {np.shape(hts)[1]} loci likelihoods to {savepath}\")\n",
    "    \n",
    "    if len(p)>0:\n",
    "        savepath = os.path.join(folder,\"p.tsv\")\n",
    "        np.savetxt(savepath, p, delimiter=delimiter)\n",
    "        print(f\"Saved {len(p)} allele frequencies to {savepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test single Haplotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of derived variants: 4995 / 10000\n",
      "Number of derived variants haplotype ll: 4995 / 10000\n"
     ]
    }
   ],
   "source": [
    "p = draw_normal_all_freqs(l=10000, mean=0.5, std=0.1)\n",
    "assert((np.min(p)>0) and (np.max(p)<1)) # Sanity Check\n",
    "\n",
    "### Draw random Haplotype\n",
    "h0 = draw_haplotype(p)\n",
    "print(f\"Number of derived variants: {np.sum(h0)} / {len(h0)}\")\n",
    "l0 = create_hap_ll(h0)\n",
    "print(f\"Number of derived variants haplotype ll: {np.sum(l0[:,1])} / {len(l0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create IBD sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.28 ms, sys: 616 Âµs, total: 5.9 ms\n",
      "Wall time: 4.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "p, htsl = create_ibd_haplos(l=10000, loc=[2000,4000], mean=0.5, std=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 loci likelihoods to ./output/simulated/undermodel/sim1/haplo_ll.tsv\n",
      "Saved 10000 allele frequencies to ./output/simulated/undermodel/sim1/p.tsv\n"
     ]
    }
   ],
   "source": [
    "save_haplo_ll(hts=hts, p=p, folder=\"./output/simulated/undermodel/sim1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test load the saved the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "htsl1 = np.loadtxt(\"./output/simulated/undermodel/sim1/haplo_ll.tsv\", delimiter=\"\\t\", dtype=\"float\")\n",
    "p1 = np.loadtxt(\"./output/simulated/undermodel/sim1/p.tsv\", delimiter=\"\\t\", dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

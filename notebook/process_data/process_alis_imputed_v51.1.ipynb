{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the v51.1 Data into hdf5\n",
    "### Prepare Imputed Genotype Files in HDF5 Format\n",
    "Uses imported function from vcf_to_hdf5.py\n",
    "The original version can be found in `process_alis_imputed_v43.ipynb`\n",
    "\n",
    "### Here: Test Run for Chromosome 22\n",
    "Then port this function into './cluster' for a run on O2 for chromosome 1-21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM O2 Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/hapBLOCK\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import allel\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.insert(0, \"/n/groups/reich/hringbauer/git/hapBLOCK/python3/prepare\")  # hack to get local package first in path\n",
    "from prepare_h5 import vcf_to_1240K_hdf\n",
    "\n",
    "\n",
    "#from hapsburg.PackagesSupport.h5_python.h5_functions import merge_in_ld_map\n",
    "#sys.path.append(\"/n/groups/reich/hringbauer/git/hapBLOCK/python3/\")\n",
    "#from IO.h5_modify import merge_in_af, get_af, get_af1000G, lift_af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all steps of the transformation for whole Chromosomes bundled up\n",
    "Ultimately loop over multiple chromosomes. \n",
    "\n",
    "Can **run in parallel**: See `./cluster/vcf_to_hdf5.py`\n",
    "\n",
    "\n",
    "Takes about 2 hours for long chromosome\n",
    "\n",
    "40 minutes for Chr. 22 (v51.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v51.1 description from Ali\n",
    "/n/data1/hms/genetics/reich/1000Genomes/ali/WholeGenomeImputation/imputed_r2/v51.1\n",
    "\n",
    "        ./chr*.bcf files contain all 1000GP phase 3 biallelic variants (SNPs and indels).\n",
    "        ./1240k/autosomes.bcf file contains 1240k SNPs for 22 autosomes combined in a single file.\n",
    "\n",
    "\n",
    "Below is a brief description of the file format.\n",
    "\n",
    "<<<\n",
    "Imputed file format is BCF with following fields:\n",
    "\n",
    "Generated by imputation tool (glimpse):\n",
    "    GT: Phased and imputed genotypes\n",
    "    DS: Genotype dosage\n",
    "    GP: Genotype posteriors\n",
    "Generated by genotype caller (mpileup):\n",
    "    PL: Phred-scaled genotype likelihoods\n",
    "    AD: Allelic depths (high-quality bases)\n",
    "\n",
    "\n",
    "* Note that PL and AD are available when the target variant is covered by at least one read otherwise their value is missed.\n",
    "* To minimize the reference bias only PL of SNPs are used to build imputation model for both SNPs and indels. Nevertheless, PL and AD for indels are also reported in the output.\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/n/groups/reich/ali/WholeGenomeImputation/imputed/v49.2\"\n",
    "\"/n/data1/hms/genetics/reich/1000Genomes/ali/WholeGenomeImputation/imputed_r2/v51.1\" # does not work (no read access...)\n",
    "\n",
    "\"/n/data1/hms/genetics/reich/1000Genomes/ali/WholeGenomeImputation/imputed_r2/v51.1/\" # Now Works (as of May 16th 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print downsampling to 1240K...\n",
      "Finished BCF tools filtering.\n",
      "Converting to HDF5...\n",
      "Finished conversion to hdf5!\n",
      "Merging in LD Map..\n",
      "Lifting LD Map from eigenstrat to HDF5...\n",
      "Loaded 15483 variants.\n",
      "Loaded 23735 individuals.\n",
      "Loaded 16420 Chr.22 1240K SNPs.\n",
      "Intersection 15408 out of 15483 HDF5 SNPs\n",
      "Interpolating 75 variants.\n",
      "Finished Chromosome 22.\n",
      "Adding map to HDF5...\n",
      "We did it. Finished.\n",
      "Merging in Allele Frequencies\n",
      "Adding map to HDF5...\n",
      "Loaded 15483 variants.\n",
      "Finshed merged in allele frequencies into /n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v51.1/ch22.h5\n",
      "Finished running chromosome 22\n",
      "CPU times: user 9min 13s, sys: 48.2 s, total: 10min 1s\n",
      "Wall time: 40min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch = 22\n",
    "vrs = \"51.1\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "vcf_to_1240K_hdf(in_vcf_path = f\"/n/data1/hms/genetics/reich/1000Genomes/ali/WholeGenomeImputation/imputed_r2/v{vrs}/chr{ch}.bcf\",\n",
    "                 path_vcf = f\"{base_path}/data/vcf/1240k_v{vrs}/ch{ch}.vcf.gz\",\n",
    "                 path_h5 = f\"{base_path}/data/hdf5/1240k_v{vrs}/ch{ch}.h5\",\n",
    "                 marker_path = f\"{base_path}/data/filters/1240K_1000G/snps_bcftools_ch{ch}.csv\",\n",
    "                 map_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/1240k/v{vrs}_1240k.snp\", buffer_size=20000,\n",
    "                 chunk_width=8, chunk_length=20000,\n",
    "                 ch=ch)\n",
    "\n",
    "print(f\"Finished running chromosome {ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task: Merge all vcfs into master vcf and create one master hdf5\n",
    "Needed e.g. for Fst calculation\n",
    "Takes about ~5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vcfs(in_vcf_paths=[], out_vcf_path=\"\"):\n",
    "    \"\"\"Merges Set of VCFs into one VCF. \n",
    "    in_vcf_paths: List of VCFs to merge\n",
    "    out_vcf_path: Output of VCF\"\"\"\n",
    "    paths_merge = \" \".join(in_vcf_paths)\n",
    "    !bcftools concat -n -o $out_vcf_path $paths_merge\n",
    "    print(\"Finished BCF tools filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the headers of 22 files.\n",
      "Done, the headers are compatible.\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch1.vcf.gz\t57.157292 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch2.vcf.gz\t53.625306 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch3.vcf.gz\t50.910228 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch4.vcf.gz\t32.858806 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch5.vcf.gz\t63.243209 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch6.vcf.gz\t43.311915 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch7.vcf.gz\t26.023809 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch8.vcf.gz\t60.150605 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch9.vcf.gz\t34.420143 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch10.vcf.gz\t31.067965 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch11.vcf.gz\t48.944901 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch12.vcf.gz\t21.056237 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch21.vcf.gz\t9.016085 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch22.vcf.gz\t7.188044 seconds\n",
      "Finished BCF tools filtering.\n",
      "CPU times: user 16.9 s, sys: 3.53 s, total: 20.5 s\n",
      "Wall time: 12min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Step 1: Merge all VCFs\n",
    "base_folder_vcf = \"./data/vcf/1240k_v46.2/ch\"\n",
    "out_vcf_path = \"./data/vcf/1240k_v49.2/all_ch.vcf.gz\"\n",
    "paths_vcf = [base_folder_vcf + str(ch) + \".vcf.gz\" for ch in range(1,23)]\n",
    "\n",
    "merge_vcfs(in_vcf_paths=paths_vcf, out_vcf_path=out_vcf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now transform the whole data to hdf5\n",
    "Takes 8 hours. Ouch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out_path_h5=\"./data/hdf5/1240k_v49.2/all_ch.h5\"\n",
    "allel.vcf_to_hdf5(input=out_vcf_path, output=out_path_h5, chunk_length=10000, chunk_width=8,\n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes 7h30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Create Variant only VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index vcf file  -t\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "!bcftools index -f $vcf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "vcf_var_only = \"./data/vcf/1240k_v43/1240k_vars.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools view -G -o $vcf_var_only $vcf_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Test code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##fileDate=15/07/2020 - 20:20:41\n",
      "##source=GLIMPSE_phase v1.0.0\n",
      "##contig=<ID=21>\n",
      "##INFO=<ID=RAF,Number=A,Type=Float,Description=\"ALT allele frequency in the reference panel\">\n",
      "##INFO=<ID=AF,Number=A,Type=Float,Description=\"ALT allele frequency computed from DS/GP field across target samples\">\n",
      "##INFO=<ID=INFO,Number=A,Type=Float,Description=\"Imputation information or quality score\">\n",
      "##INFO=<ID=BUF,Number=A,Type=Integer,Description=\"Is it a variant site falling within buffer regions? (0=no/1=yes)\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Unphased genotypes\">\n",
      "##FORMAT=<ID=DS,Number=1,Type=Float,Description=\"Genotype dosage\">\n",
      "##FORMAT=<ID=GP,Number=3,Type=Float,Description=\"Genotype posteriors\">\n",
      "##FORMAT=<ID=HS,Number=1,Type=Integer,Description=\"Sampled haplotype pairs packed into intergers (max: 15 pairs, see NMAIN header line)\">\n",
      "##NMAIN=10\n",
      "##bcftools_annotateVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased.bcf -c FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/ligate.bcf; Date=Wed Jul 15 20:35:52 2020\n",
      "##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"List of Phred-scaled genotype likelihoods\">\n",
      "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths (high-quality bases)\">\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/annotation.bcf -c ^FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/glimpse_mpileup.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf; Date=Wed Jul 15 20:35:57 2020\n",
      "##bcftools_mergeVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0.bcf -Ob; Date=Tue Jul 21 22:06:48 2020\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks.bcf -Ob; Date=Wed Jul 22 01:38:29 2020\n",
      "##bcftools_viewVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_viewCommand=view -Oz -o /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz -T /n/groups/reich/hringbauer/git/hapBLOCK/data/filters/1240K_1000G/snps_bcftools_ch21.csv -M2 -v snps /n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr21.bcf; Date=Thu Oct  1 00:39:19 2020\n",
      "##bcftools_viewCommand=view /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz; Date=Sat Mar 27 08:56:41 2021\n",
      "[main_vcfview] Error: cannot write to (null)\n"
     ]
    }
   ],
   "source": [
    "### index vcf file  -t\n",
    "test = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\"\n",
    "\n",
    "ch = 21\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "test = f\"{base_path}/data/vcf/1240k_v43/ch{ch}.vcf.gz\" #v46.2\n",
    "!bcftools view $test | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16031\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -f '%POS\\n' $test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14523\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -l $test | wc -l # 19260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Created HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'AF_ALL', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "['AD', 'DS', 'GP', 'GT', 'HS', 'PL']\n",
      "(15483, 23735, 2)\n",
      "CPU times: user 22.5 ms, sys: 6.08 ms, total: 28.6 ms\n",
      "Wall time: 34.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch=22\n",
    "with h5py.File(f\"./data/hdf5/1240k_v51.1/ch{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "    gp = f[\"calldata/GP\"][:,0,:]\n",
    "    gt = f[\"calldata/GT\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'AF_ALL', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "['AD', 'DS', 'GP', 'GT', 'HS', 'PL']\n",
      "(89082, 21255, 2)\n",
      "CPU times: user 27 ms, sys: 5.55 ms, total: 32.6 ms\n",
      "Wall time: 46 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with h5py.File(f\"./data/hdf5/1240k_v49.2/ch1.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "    #gp = f[\"calldata/GP\"][:,0,:]\n",
    "    #gt = f[\"calldata/GT\"][:,0,:]\n",
    "    ad = f[\"calldata/AD\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = range(30000,30200)\n",
    "j = 12483\n",
    "ads = f[\"calldata/AD\"][snps, j, :2]\n",
    "gts = f[\"calldata/GT\"][snps, j, :]\n",
    "gp = f[\"calldata/GP\"][snps, j, :]\n",
    "df = pd.DataFrame({\"ref\":ads[:,0], \"alt\":ads[:,1], \"gt0\":np.sum(gts, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

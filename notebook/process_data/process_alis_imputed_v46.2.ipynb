{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Imputed Genotype Files in HDF5 Format\n",
    "Uses imported function from vcf_to_hdf5.py\n",
    "The original version can be found in `process_alis_imputed_v43.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import allel\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.insert(0, \"/n/groups/reich/hringbauer/git/hapBLOCK/python3/prepare\")  # hack to get local package first in path\n",
    "from prepare_h5 import vcf_to_1240K_hdf\n",
    "#from hapsburg.PackagesSupport.h5_python.h5_functions import merge_in_ld_map\n",
    "#sys.path.append(\"/n/groups/reich/hringbauer/git/hapBLOCK/python3/\")\n",
    "#from IO.h5_modify import merge_in_af, get_af, get_af1000G, lift_af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all steps of the transformation for whole Chromosomes bundled up\n",
    "Ultimately loop over multiple chromosomes or run in paralle (see `./cluster/vcf_to_hdf5.py`)\n",
    "Takes about 2 hours for long chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print downsampling to 1240K...\n",
      "Converting to HDF5...\n",
      "Finished conversion to hdf5!\n",
      "Merging in LD Map..\n",
      "Lifting LD Map from eigenstrat to HDF5...\n",
      "Loaded 15793 variants.\n",
      "Loaded 19260 individuals.\n",
      "Loaded 16420 Chr.22 1240K SNPs.\n",
      "Intersection 15793 out of 15793 HDF5 SNPs\n",
      "Finished Chromosome 22.\n",
      "Adding map to HDF5...\n",
      "We did it. Finished.\n",
      "Merging in Allele Frequencies\n",
      "Adding map to HDF5...\n",
      "Loaded 15793 variants.\n",
      "Finshed merged in allele frequencies into /n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v46.2/ch22.h5\n",
      "Finished running chromosome 22\n",
      "CPU times: user 6min 45s, sys: 11.3 s, total: 6min 57s\n",
      "Wall time: 7min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch = 22\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "vcf_to_1240K_hdf(in_vcf_path = f\"/n/groups/reich/ali/WholeGenomeImputation/imputed/v46.2/chr{ch}.bcf\",\n",
    "                 path_vcf = f\"{base_path}/data/vcf/1240k_v46.2/ch{ch}.vcf.gz\",\n",
    "                 path_h5 = f\"{base_path}/data/hdf5/1240k_v46.2/ch{ch}.h5\",\n",
    "                 marker_path = f\"{base_path}/data/filters/1240K_1000G/snps_bcftools_ch{ch}.csv\",\n",
    "                 map_path = f\"/n/groups/reich/DAVID/V46/V46.2/v46.2.snp\", buffer_size=20000,\n",
    "                 chunk_width=8, chunk_length=20000,\n",
    "                 ch=ch)\n",
    "\n",
    "print(f\"Finished running chromosome {ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task: Merge all vcfs into master vcf and create one master hdf5\n",
    "Takes about ~5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the headers of 22 files.\n",
      "Done, the headers are compatible.\n",
      "Concatenating ./data/vcf/1240k_v43/ch1.vcf.gz\t30.639150 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch2.vcf.gz\t45.643698 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch3.vcf.gz\t36.244412 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch4.vcf.gz\t24.110753 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch5.vcf.gz\t15.251328 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch6.vcf.gz\t38.759324 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch7.vcf.gz\t22.824363 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch8.vcf.gz\t29.042413 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch9.vcf.gz\t14.210376 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch10.vcf.gz\t13.008295 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch11.vcf.gz\t26.994599 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch12.vcf.gz\t25.384168 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch13.vcf.gz\t15.094192 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch14.vcf.gz\t9.998397 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch15.vcf.gz\t13.863428 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch16.vcf.gz\t20.042137 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch17.vcf.gz\t9.150381 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch18.vcf.gz\t6.815559 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch19.vcf.gz\t15.200667 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch20.vcf.gz\t14.880735 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch21.vcf.gz\t2.451040 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch22.vcf.gz\t8.150736 seconds\n",
      "Finished BCF tools filtering.\n",
      "CPU times: user 11.6 s, sys: 2.68 s, total: 14.2 s\n",
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_folder_vcf = \"./data/vcf/1240k_v43/ch\"\n",
    "out_vcf_path = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "paths_vcf = [base_folder_vcf + str(ch) + \".vcf.gz\" for ch in range(1,23)]\n",
    "\n",
    "merge_vcfs(in_vcf_paths=paths_vcf, out_vcf_path=out_vcf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now transform the whole data to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 59min 46s, sys: 23min, total: 7h 22min 47s\n",
      "Wall time: 7h 24min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out_path_h5=\"./data/hdf5/1240k_v43/all_ch.h5\"\n",
    "allel.vcf_to_hdf5(input=out_vcf_path, output=out_path_h5, chunk_length=10000, chunk_width=8,\n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes 7h30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Create Variant only VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index vcf file  -t\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "!bcftools index -f $vcf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "vcf_var_only = \"./data/vcf/1240k_v43/1240k_vars.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools view -G -o $vcf_var_only $vcf_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Test code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##fileDate=15/07/2020 - 20:20:41\n",
      "##source=GLIMPSE_phase v1.0.0\n",
      "##contig=<ID=21>\n",
      "##INFO=<ID=RAF,Number=A,Type=Float,Description=\"ALT allele frequency in the reference panel\">\n",
      "##INFO=<ID=AF,Number=A,Type=Float,Description=\"ALT allele frequency computed from DS/GP field across target samples\">\n",
      "##INFO=<ID=INFO,Number=A,Type=Float,Description=\"Imputation information or quality score\">\n",
      "##INFO=<ID=BUF,Number=A,Type=Integer,Description=\"Is it a variant site falling within buffer regions? (0=no/1=yes)\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Unphased genotypes\">\n",
      "##FORMAT=<ID=DS,Number=1,Type=Float,Description=\"Genotype dosage\">\n",
      "##FORMAT=<ID=GP,Number=3,Type=Float,Description=\"Genotype posteriors\">\n",
      "##FORMAT=<ID=HS,Number=1,Type=Integer,Description=\"Sampled haplotype pairs packed into intergers (max: 15 pairs, see NMAIN header line)\">\n",
      "##NMAIN=10\n",
      "##bcftools_annotateVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased.bcf -c FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/ligate.bcf; Date=Wed Jul 15 20:35:52 2020\n",
      "##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"List of Phred-scaled genotype likelihoods\">\n",
      "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths (high-quality bases)\">\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/annotation.bcf -c ^FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/glimpse_mpileup.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf; Date=Wed Jul 15 20:35:57 2020\n",
      "##bcftools_mergeVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0.bcf -Ob; Date=Tue Jul 21 22:06:48 2020\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks.bcf -Ob; Date=Wed Jul 22 01:38:29 2020\n",
      "##bcftools_viewVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_viewCommand=view -Oz -o /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz -T /n/groups/reich/hringbauer/git/hapBLOCK/data/filters/1240K_1000G/snps_bcftools_ch21.csv -M2 -v snps /n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr21.bcf; Date=Thu Oct  1 00:39:19 2020\n",
      "##bcftools_viewCommand=view /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz; Date=Sat Mar 27 08:56:41 2021\n",
      "[main_vcfview] Error: cannot write to (null)\n"
     ]
    }
   ],
   "source": [
    "### index vcf file  -t\n",
    "test = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\"\n",
    "\n",
    "ch = 21\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "test = f\"{base_path}/data/vcf/1240k_v43/ch{ch}.vcf.gz\" #v46.2\n",
    "!bcftools view $test | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16031\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -f '%POS\\n' $test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14523\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -l $test | wc -l # 19260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Created HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'AF_ALL', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "['AD', 'DS', 'GP', 'GT', 'HS', 'PL']\n",
      "(15793, 19260, 2)\n",
      "CPU times: user 9.2 ms, sys: 2.1 ms, total: 11.3 ms\n",
      "Wall time: 12.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch=22\n",
    "with h5py.File(f\"./data/hdf5/1240k_v46.2/ch{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "#g = h5py.File(\"./data/hdf5/HO_v43/ch3.h5\", \"r\")\n",
    "    gt = f[\"calldata/GT\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5py' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h5py' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch=22\n",
    "with h5py.File(f\"./data/hdf5/1240k_v46.2/ch{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "#g = h5py.File(\"./data/hdf5/HO_v43/ch3.h5\", \"r\")\n",
    "    gp = f[\"calldata/GP\"][:,0,:]\n",
    "    gt = f[\"calldata/GT\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47705, 14523, 2)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(f\"./data/hdf5/HO_v43/ch{ch}.h5\", \"r\") as f:\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12483    MA89\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.Series(f[\"samples\"][:])\n",
    "samples[samples.str.contains(\"MA89\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = range(30000,30200)\n",
    "j = 12483\n",
    "ads = f[\"calldata/AD\"][snps, j, :2]\n",
    "gts = f[\"calldata/GT\"][snps, j, :]\n",
    "gp = f[\"calldata/GP\"][snps, j, :]\n",
    "df = pd.DataFrame({\"ref\":ads[:,0], \"alt\":ads[:,1], \"gt0\":np.sum(gts, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  h5py.File(f\"./data/hdf5/1240k_v43/all_ch.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100313, 14523, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(f[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.value_counts(f[\"variants/CHROM\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

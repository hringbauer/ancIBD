{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the v43.4 Data into hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-a-16-161.o2.rc.hms.harvard.edu\n",
      "HSM O2 Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/hapBLOCK\n",
      "CPU Count: 32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import allel\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.insert(0, \"/n/groups/reich/hringbauer/git/HAPSBURG/package/\")  # hack to get local package first in path\n",
    "from hapsburg.PackagesSupport.h5_python.h5_functions import merge_in_ld_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_ali_vcf = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\"\n",
    "path_ali_stats = \"/n/groups/reich/ali/chromosome_abnormality/coverage_stats_v43.4.tsv\"\n",
    "### Read Ali's coverage stats\n",
    "#df = pd.read_csv(\"/n/groups/reich/ali/chromosome_abnormality/coverage_stats_v43.4.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downsample to 1240K data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_1240kmarkers(snp1240k_path=\"\", marker_path=\"\", ch=0):\n",
    "    \"\"\"Save all 1240 Markers of .snp eigenstrat file.\n",
    "    to marker_path.\n",
    "    ch: Chromosome. If null filter all of them\"\"\"\n",
    "    df_snp = pd.read_csv(snp1240k_path, header=None, sep=r\"\\s+\", engine=\"python\")\n",
    "    df_snp.columns = [\"SNP\", \"chr\", \"map\", \"pos\", \"ref\", \"alt\"]\n",
    "    if ch>0:\n",
    "        df_snp = df_snp[df_snp[\"chr\"] == ch]\n",
    "    print(f\"Loaded {len(df_snp)} Chr.{ch} SNPs.\")\n",
    "\n",
    "    df_save = df_snp[[\"chr\", \"pos\"]]\n",
    "    df_save.to_csv(marker_path, sep=\"\\t\", header=None, index=False)\n",
    "    print(f\"Saved {len(df_save)} 1240k Markers on Chr. {ch} to {marker_path}\")\n",
    "    \n",
    "def save_1240_1000g_kmarkers(ch=3, snp_path=\"\", marker_path=\"\"):\n",
    "    \"\"\"Save all 1240 and 1000G Markers of .snp eigenstrat file.\n",
    "    to marker_path. Loads Ali Path file\n",
    "    snp_path: Where to find the SNPs plus their types\"\"\"\n",
    "    df1=pd.read_csv(snp_path, sep=\"\\t\", header=None)\n",
    "    df1.columns=[\"chr\", \"pos\", \"pos1\", \"ref\", \"alt\", \"type\"]\n",
    "    print(f\"Loaded {len(df1)} SNPs on Chr. {ch}\")\n",
    "    df2 = df1[df1[\"type\"]==\"1kg+1240k\"]\n",
    "    print(f\"Loaded {len(df2)} Chr.{ch} SNPs in both 1240K and 1000G.\")\n",
    "    df_save = df2[[\"chr\", \"pos1\"]]\n",
    "    df_save.to_csv(marker_path, sep=\"\\t\", header=None, index=False)\n",
    "    print(f\"Saved {len(df_save)} 1240k+1000G Markers on Chr. {ch} to {marker_path}\")\n",
    "    \n",
    "def bctools_filter_vcf(in_vcf_path=\"\", out_vcf_path=\"\", marker_path=\"\"):\n",
    "    \"\"\"Same as PLINK, but with bcftools and directly via Marker Positions.\n",
    "    filter_iids: Whether to use the .csv with Indivdiduals to extract\"\"\"\n",
    "    !bcftools view -Oz -o $out_vcf_path -T $marker_path -M2 -v snps $in_vcf_path\n",
    "    print(\"Finished BCF tools filtering.\")\n",
    "    \n",
    "def bctools_filter_vcf_allvariants(in_vcf_path=\"\", out_vcf_path=\"\", marker_path=\"\"):\n",
    "    \"\"\"Same as PLINK, but with bcftools and directly via Marker Positions.\n",
    "    filter_iids: Whether to use the .csv with Indivdiduals to extract\"\"\"\n",
    "    !bcftools view -Oz -o $out_vcf_path -T $marker_path -v snps $in_vcf_path\n",
    "    print(\"Finished BCF tools filtering.\")\n",
    "    \n",
    "def merge_vcfs(in_vcf_paths=[], out_vcf_path=\"\"):\n",
    "    \"\"\"Merges Set of VCFs into one VCF. \n",
    "    in_vcf_paths: List of VCFs to merge\n",
    "    out_vcf_path: Output of VCF\"\"\"\n",
    "    paths_merge = \" \".join(in_vcf_paths)\n",
    "    !bcftools concat -n -o $out_vcf_path $paths_merge\n",
    "    print(\"Finished BCF tools filtering.\")\n",
    "    \n",
    "##############################################################\n",
    "### Function Identical to vcf_to_hdf5.py in cluster/ folder\n",
    "\n",
    "def vcf_to_1240K_hdf(in_vcf_path = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\",\n",
    "                     path_vcf = \"./data/vcf/1240k_v43/ch3.vcf.gz\",\n",
    "                     path_h5 = \"./data/hdf5/1240k_v43/ch3.h5\",\n",
    "                     marker_path=\"./data/filters/ho_snps_bcftools_ch3.csv\",\n",
    "                     map_path=\"/n/groups/reich/DAVID/V43/V43.5/v43.5.snp\",\n",
    "                     ch=3):\n",
    "    \"\"\"Convert Ali's vcf to 1240K hdf5. \n",
    "    If marker_path empty, no SNP filtering done.\n",
    "    If map_path empty, no genetic map is merged in.\n",
    "    \"\"\" \n",
    "    if len(marker_path)>0:\n",
    "        bctools_filter_vcf(in_vcf_path = in_vcf_path,\n",
    "                           out_vcf_path= path_vcf,\n",
    "                           marker_path = marker_path)\n",
    "    print(\"Finished downsampling to 1240K\")\n",
    "    \n",
    "    allel.vcf_to_hdf5(input=path_vcf, output=path_h5, \n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], \n",
    "                      types={'samples': 'S32'},\n",
    "                      compression=\"gzip\") # Do the conversion to hdf5. Takes hours\n",
    "    print(\"Finished conversion to hdf5!\")\n",
    "    \n",
    "    if len(map_path)>0:\n",
    "        merge_in_ld_map(path_h5=path_h5, \n",
    "                    path_snp1240k=map_path,\n",
    "                    chs=[ch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare HO and 1240K and 1240K 1000 G Markers [Finished]\n",
    "Takes about 3 min for all autosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Same but for HO SNPs\n",
    "for ch in range(1,23):\n",
    "    save_1240kmarkers(snp1240k_path=\"/n/groups/reich/DAVID/V43/V43.5/v43.5_HO.snp\",\n",
    "                      marker_path=f\"./data/filters/ho_snps_bcftools_ch{ch}.csv\",\n",
    "                      ch=ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Same but for HO SNPs\n",
    "for ch in range(1,23):\n",
    "    save_1240kmarkers(snp1240k_path=\"/n/groups/reich/DAVID/V43/V43.5/v43.5.snp\",\n",
    "                      marker_path=f\"./data/filters/1240K_snps_bcftools_ch{ch}.csv\",\n",
    "                      ch=ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "### Save only SNPs in 1240K and 1000G\n",
    "for ch in range(1,23):\n",
    "    save_1240_1000g_kmarkers(snp_path=f\"/n/groups/reich/datasets/1kg/snps_1kg_1240k/chr{ch}.bed\",\n",
    "                             marker_path=f\"./data/filters/1240K_1000G/snps_bcftools_ch{ch}.csv\",\n",
    "                             ch=ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run through one chromosome: vcf -> 1240K vcf -> hdf5\n",
    "Mainly to test timing, and prepare what is about to follow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To 1240K VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Finished BCF tools filtering.\n",
      "CPU times: user 1.6 s, sys: 344 ms, total: 1.94 s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bctools_filter_vcf(in_vcf_path = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\",\n",
    "                   out_vcf_path= \"./data/vcf/1240k_v43/ch3.vcf.gz\",\n",
    "                   marker_path = \"./data/filters/1240K_snps_bcftools_ch3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished\n"
     ]
    }
   ],
   "source": [
    "print(f\"Run finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert VCF to HDF5\n",
    "Takes about 15min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path_vcf = \"./data/vcf/1240k_v43/ch1.vcf.gz\"\n",
    "path_h5 = \"./data/hdf5/1240k_v43/ch1.h5\"\n",
    "\n",
    "allel.vcf_to_hdf5(input=path_vcf, output=path_h5, \n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes hours\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished transformation to hdf5\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished transformation to hdf5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge in genetic map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time\n",
    "merge_in_ld_map(path_h5=\"./data/hdf5/1240k_v43/ch1.h5\", \n",
    "                path_snp1240k=\"/n/groups/reich/DAVID/V43/V43.5/v43.5.snp\",\n",
    "                chs=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To 1240K VCF with all variants\n",
    "vcf filterting takes about 2h for long chromosome\n",
    "\n",
    "Transformation to hdf5 takes about 15 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "bctools_filter_vcf_allvariants(in_vcf_path = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\",\n",
    "                               out_vcf_path= \"./data/vcf/1240k_v43_allsnps/ch3.vcf.gz\",\n",
    "                               marker_path = \"./data/filters/ho_snps_bcftools_ch3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n",
      "CPU times: user 15min 53s, sys: 1min 16s, total: 17min 10s\n",
      "Wall time: 17min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_vcf = \"./data/vcf/1240k_v43_allsnps/ch3.vcf.gz\"\n",
    "path_h5 = \"./data/hdf5/1240k_v43_allsnps/ch3.h5\"\n",
    "\n",
    "allel.vcf_to_hdf5(input=path_vcf, output=path_h5, \n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes hours\n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All steps of the transformation to transformation of whole Chromosomes bundled up\n",
    "To loop over multiple chromosomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "vcf_to_1240K_hdf(in_vcf_path = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr4.bcf\",\n",
    "                 path_vcf = \"./data/vcf/1240k_v43/ch4.vcf.gz\",\n",
    "                 path_h5 = \"./data/hdf5/1240k_v43/ch4.h5\",\n",
    "                 marker_path=\"./data/filters/ho_snps_bcftools_ch4.csv\",\n",
    "                 map_path=\"/n/groups/reich/DAVID/V43/V43.5/v43.5.snp\",\n",
    "                 ch=4)\n",
    "print(f\"Finished running one chromosome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task: Merge all vcfs into master vcf and create one master hdf5\n",
    "Takes about ~5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the headers of 22 files.\n",
      "Done, the headers are compatible.\n",
      "Concatenating ./data/vcf/1240k_v43/ch1.vcf.gz\t30.639150 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch2.vcf.gz\t45.643698 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch3.vcf.gz\t36.244412 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch4.vcf.gz\t24.110753 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch5.vcf.gz\t15.251328 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch6.vcf.gz\t38.759324 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch7.vcf.gz\t22.824363 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch8.vcf.gz\t29.042413 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch9.vcf.gz\t14.210376 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch10.vcf.gz\t13.008295 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch11.vcf.gz\t26.994599 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch12.vcf.gz\t25.384168 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch13.vcf.gz\t15.094192 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch14.vcf.gz\t9.998397 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch15.vcf.gz\t13.863428 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch16.vcf.gz\t20.042137 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch17.vcf.gz\t9.150381 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch18.vcf.gz\t6.815559 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch19.vcf.gz\t15.200667 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch20.vcf.gz\t14.880735 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch21.vcf.gz\t2.451040 seconds\n",
      "Concatenating ./data/vcf/1240k_v43/ch22.vcf.gz\t8.150736 seconds\n",
      "Finished BCF tools filtering.\n",
      "CPU times: user 11.6 s, sys: 2.68 s, total: 14.2 s\n",
      "Wall time: 7min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "base_folder_vcf = \"./data/vcf/1240k_v43/ch\"\n",
    "out_vcf_path = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "paths_vcf = [base_folder_vcf + str(ch) + \".vcf.gz\" for ch in range(1,23)]\n",
    "\n",
    "merge_vcfs(in_vcf_paths=paths_vcf, out_vcf_path=out_vcf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now transform the whole data to hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6h 59min 46s, sys: 23min, total: 7h 22min 47s\n",
      "Wall time: 7h 24min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out_path_h5=\"./data/hdf5/1240k_v43/all_ch.h5\"\n",
    "allel.vcf_to_hdf5(input=out_vcf_path, output=out_path_h5, chunk_length=10000, chunk_width=8,\n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes 7h30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Create Variant only VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index vcf file  -t\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "!bcftools index -f $vcf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "vcf_var_only = \"./data/vcf/1240k_v43/1240k_vars.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools view -G -o $vcf_var_only $vcf_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Test code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index vcf file  -t\n",
    "test = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\"\n",
    "!bcftools view $test | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100313\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -f '%POS\\n' $vcf_var_only | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "(89082, 14523, 2)\n"
     ]
    }
   ],
   "source": [
    "ch=1\n",
    "with h5py.File(f\"./data/hdf5/1240k_v43/ch{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "#g = h5py.File(\"./data/hdf5/HO_v43/ch3.h5\", \"r\")\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47705, 14523, 2)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(f\"./data/hdf5/HO_v43/ch{ch}.h5\", \"r\") as f:\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12483    MA89\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = pd.Series(f[\"samples\"][:])\n",
    "samples[samples.str.contains(\"MA89\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = range(30000,30200)\n",
    "j = 12483\n",
    "ads = f[\"calldata/AD\"][snps, j, :2]\n",
    "gts = f[\"calldata/GT\"][snps, j, :]\n",
    "gp = f[\"calldata/GP\"][snps, j, :]\n",
    "df = pd.DataFrame({\"ref\":ads[:,0], \"alt\":ads[:,1], \"gt0\":np.sum(gts, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f =  h5py.File(f\"./data/hdf5/1240k_v43/all_ch.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1100313, 14523, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(f[\"calldata/GT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     94173\n",
       "1     89082\n",
       "3     77601\n",
       "6     75816\n",
       "5     69354\n",
       "4     68720\n",
       "8     61091\n",
       "7     59836\n",
       "10    58763\n",
       "11    54796\n",
       "12    53884\n",
       "9     50629\n",
       "13    38994\n",
       "14    36280\n",
       "15    34407\n",
       "16    34375\n",
       "18    33902\n",
       "17    29292\n",
       "20    29053\n",
       "19    18441\n",
       "21    16031\n",
       "22    15793\n",
       "Name: /variants/CHROM, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(f[\"variants/CHROM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Allele Frequencies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

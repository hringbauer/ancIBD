{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the v43.4 Data into hdf5\n",
    "### Prepare Imputed Genotype Files in HDF5 Format\n",
    "Uses imported function from vcf_to_hdf5.py\n",
    "The original version can be found in `process_alis_imputed_v43.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM O2 Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/hapBLOCK\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import h5py\n",
    "import allel\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "print(os.getcwd())\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")\n",
    "\n",
    "sys.path.insert(0, \"/n/groups/reich/hringbauer/git/hapBLOCK/python3/prepare\")  # hack to get local package first in path\n",
    "from prepare_h5 import vcf_to_1240K_hdf\n",
    "#from hapsburg.PackagesSupport.h5_python.h5_functions import merge_in_ld_map\n",
    "#sys.path.append(\"/n/groups/reich/hringbauer/git/hapBLOCK/python3/\")\n",
    "#from IO.h5_modify import merge_in_af, get_af, get_af1000G, lift_af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run all steps of the transformation for whole Chromosomes bundled up\n",
    "Ultimately loop over multiple chromosomes. \n",
    "\n",
    "Can **run in parallel**: See `./cluster/vcf_to_hdf5.py`\n",
    "\n",
    "\n",
    "Takes about 2 hours for long chromosome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/n/groups/reich/ali/WholeGenomeImputation/imputed/v49.2\n",
    "\n",
    "./chr*.bcf files contain all 1000GP phase 3 biallelic variants (SNPs and indels).\n",
    "./1240k/autosomes.bcf file contains 1240k SNPs for 22 autosomes combined in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print downsampling to 1240K...\n",
      "Finished BCF tools filtering.\n",
      "Converting to HDF5...\n",
      "Finished conversion to hdf5!\n",
      "Merging in LD Map..\n",
      "Lifting LD Map from eigenstrat to HDF5...\n",
      "Loaded 15793 variants.\n",
      "Loaded 21255 individuals.\n",
      "Loaded 16420 Chr.22 1240K SNPs.\n",
      "Intersection 15793 out of 15793 HDF5 SNPs\n",
      "Finished Chromosome 22.\n",
      "Adding map to HDF5...\n",
      "We did it. Finished.\n",
      "Merging in Allele Frequencies\n",
      "Adding map to HDF5...\n",
      "Loaded 15793 variants.\n",
      "Finshed merged in allele frequencies into /n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v49.2/ch22.h5\n",
      "Finished running chromosome 22\n",
      "CPU times: user 7min 35s, sys: 44.3 s, total: 8min 20s\n",
      "Wall time: 41min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch = 22\n",
    "vrs = \"49.2\"\n",
    "v0 = vrs.split(\".\")[0]\n",
    "\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "vcf_to_1240K_hdf(in_vcf_path = f\"/n/groups/reich/ali/WholeGenomeImputation/imputed/v{vrs}/chr{ch}.bcf\",\n",
    "                 path_vcf = f\"{base_path}/data/vcf/1240k_v{vrs}/ch{ch}.vcf.gz\",\n",
    "                 path_h5 = f\"{base_path}/data/hdf5/1240k_v{vrs}/ch{ch}.h5\",\n",
    "                 marker_path = f\"{base_path}/data/filters/1240K_1000G/snps_bcftools_ch{ch}.csv\",\n",
    "                 map_path = f\"/n/groups/reich/DAVID/V{v0}/V{vrs}/v{vrs}.snp\", buffer_size=20000,\n",
    "                 chunk_width=8, chunk_length=20000,\n",
    "                 ch=ch)\n",
    "\n",
    "print(f\"Finished running chromosome {ch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello? Blizzard?\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello? Blizzard?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Task: Merge all vcfs into master vcf and create one master hdf5\n",
    "Needed e.g. for Fst calculation\n",
    "Takes about ~5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_vcfs(in_vcf_paths=[], out_vcf_path=\"\"):\n",
    "    \"\"\"Merges Set of VCFs into one VCF. \n",
    "    in_vcf_paths: List of VCFs to merge\n",
    "    out_vcf_path: Output of VCF\"\"\"\n",
    "    paths_merge = \" \".join(in_vcf_paths)\n",
    "    !bcftools concat -n -o $out_vcf_path $paths_merge\n",
    "    print(\"Finished BCF tools filtering.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the headers of 22 files.\n",
      "Done, the headers are compatible.\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch1.vcf.gz\t57.157292 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch2.vcf.gz\t53.625306 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch3.vcf.gz\t50.910228 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch4.vcf.gz\t32.858806 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch5.vcf.gz\t63.243209 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch6.vcf.gz\t43.311915 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch7.vcf.gz\t26.023809 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch8.vcf.gz\t60.150605 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch9.vcf.gz\t34.420143 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch10.vcf.gz\t31.067965 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch11.vcf.gz\t48.944901 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch12.vcf.gz\t21.056237 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch21.vcf.gz\t9.016085 seconds\n",
      "Concatenating ./data/vcf/1240k_v46.2/ch22.vcf.gz\t7.188044 seconds\n",
      "Finished BCF tools filtering.\n",
      "CPU times: user 16.9 s, sys: 3.53 s, total: 20.5 s\n",
      "Wall time: 12min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### Step 1: Merge all VCFs\n",
    "base_folder_vcf = \"./data/vcf/1240k_v46.2/ch\"\n",
    "out_vcf_path = \"./data/vcf/1240k_v49.2/all_ch.vcf.gz\"\n",
    "paths_vcf = [base_folder_vcf + str(ch) + \".vcf.gz\" for ch in range(1,23)]\n",
    "\n",
    "merge_vcfs(in_vcf_paths=paths_vcf, out_vcf_path=out_vcf_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now transform the whole data to hdf5\n",
    "Takes 8 hours. Ouch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out_path_h5=\"./data/hdf5/1240k_v49.2/all_ch.h5\"\n",
    "allel.vcf_to_hdf5(input=out_vcf_path, output=out_path_h5, chunk_length=10000, chunk_width=8,\n",
    "                  fields = ['variants/*', 'calldata/*', \"samples\"], compression=\"gzip\") # Do the conversion to hdf5. Takes 7h30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: Create Variant only VCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### index vcf file  -t\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "!bcftools index -f $vcf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vcf_all = \"./data/vcf/1240k_v43/all_ch.vcf.gz\"\n",
    "vcf_var_only = \"./data/vcf/1240k_v43/1240k_vars.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bcftools view -G -o $vcf_var_only $vcf_all "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Area 51\n",
    "Test code here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##fileformat=VCFv4.2\n",
      "##FILTER=<ID=PASS,Description=\"All filters passed\">\n",
      "##fileDate=15/07/2020 - 20:20:41\n",
      "##source=GLIMPSE_phase v1.0.0\n",
      "##contig=<ID=21>\n",
      "##INFO=<ID=RAF,Number=A,Type=Float,Description=\"ALT allele frequency in the reference panel\">\n",
      "##INFO=<ID=AF,Number=A,Type=Float,Description=\"ALT allele frequency computed from DS/GP field across target samples\">\n",
      "##INFO=<ID=INFO,Number=A,Type=Float,Description=\"Imputation information or quality score\">\n",
      "##INFO=<ID=BUF,Number=A,Type=Integer,Description=\"Is it a variant site falling within buffer regions? (0=no/1=yes)\">\n",
      "##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Unphased genotypes\">\n",
      "##FORMAT=<ID=DS,Number=1,Type=Float,Description=\"Genotype dosage\">\n",
      "##FORMAT=<ID=GP,Number=3,Type=Float,Description=\"Genotype posteriors\">\n",
      "##FORMAT=<ID=HS,Number=1,Type=Integer,Description=\"Sampled haplotype pairs packed into intergers (max: 15 pairs, see NMAIN header line)\">\n",
      "##NMAIN=10\n",
      "##bcftools_annotateVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased.bcf -c FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/ligate.bcf; Date=Wed Jul 15 20:35:52 2020\n",
      "##FORMAT=<ID=PL,Number=G,Type=Integer,Description=\"List of Phred-scaled genotype likelihoods\">\n",
      "##FORMAT=<ID=AD,Number=R,Type=Integer,Description=\"Allelic depths (high-quality bases)\">\n",
      "##bcftools_annotateCommand=annotate -a /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/annotation.bcf -c ^FORMAT/GT -o /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/glimpse_mpileup.bcf -Ob /n/groups/reich/ali/WholeGenomeImputation/data/chr21/I0626_all/phased_imputed.bcf; Date=Wed Jul 15 20:35:57 2020\n",
      "##bcftools_mergeVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_chunk0.bcf -Ob; Date=Tue Jul 21 22:06:48 2020\n",
      "##bcftools_mergeCommand=merge -l /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks_bcf_list.txt -o /n/groups/reich/ali/WholeGenomeImputation/merged/chr21/chr21_all_chunks.bcf -Ob; Date=Wed Jul 22 01:38:29 2020\n",
      "##bcftools_viewVersion=1.10.2+htslib-1.10.2\n",
      "##bcftools_viewCommand=view -Oz -o /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz -T /n/groups/reich/hringbauer/git/hapBLOCK/data/filters/1240K_1000G/snps_bcftools_ch21.csv -M2 -v snps /n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr21.bcf; Date=Thu Oct  1 00:39:19 2020\n",
      "##bcftools_viewCommand=view /n/groups/reich/hringbauer/git/hapBLOCK/data/vcf/1240k_v43/ch21.vcf.gz; Date=Sat Mar 27 08:56:41 2021\n",
      "[main_vcfview] Error: cannot write to (null)\n"
     ]
    }
   ],
   "source": [
    "### index vcf file  -t\n",
    "test = \"/n/groups/reich/ali/WholeGenomeImputation/imputed/v43.4/chr3.bcf\"\n",
    "\n",
    "ch = 21\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "test = f\"{base_path}/data/vcf/1240k_v43/ch{ch}.vcf.gz\" #v46.2\n",
    "!bcftools view $test | head -25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16031\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -f '%POS\\n' $test | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14523\n"
     ]
    }
   ],
   "source": [
    "!bcftools query -l $test | wc -l # 19260"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Created HDF5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'AF_ALL', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "['AD', 'DS', 'GP', 'GT', 'HS', 'PL']\n",
      "(15793, 19260, 2)\n",
      "CPU times: user 24.9 ms, sys: 12.4 ms, total: 37.3 ms\n",
      "Wall time: 300 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch=22\n",
    "with h5py.File(f\"./data/hdf5/1240k_v46.2/ch{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "    gp = f[\"calldata/GP\"][:,0,:]\n",
    "    gt = f[\"calldata/GT\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n",
      "['AD', 'DS', 'GP', 'GT', 'HS', 'PL']\n",
      "(1100313, 19260, 2)\n",
      "CPU times: user 343 ms, sys: 27 ms, total: 370 ms\n",
      "Wall time: 11.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with h5py.File(f\"./data/hdf5/1240k_v49.2/all_ch.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "    #gp = f[\"calldata/GP\"][:,0,:]\n",
    "    #gt = f[\"calldata/GT\"][:,0,:]\n",
    "    ad = f[\"calldata/AD\"][:,0,:]\n",
    "    print(list(f[\"variants\"]))\n",
    "    print(list(f[\"calldata\"]))\n",
    "    print(np.shape(f[\"calldata/GT\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "snps = range(30000,30200)\n",
    "j = 12483\n",
    "ads = f[\"calldata/AD\"][snps, j, :2]\n",
    "gts = f[\"calldata/GT\"][snps, j, :]\n",
    "gp = f[\"calldata/GP\"][snps, j, :]\n",
    "df = pd.DataFrame({\"ref\":ads[:,0], \"alt\":ads[:,1], \"gt0\":np.sum(gts, axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

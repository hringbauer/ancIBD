{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Howto: Create the HDF5 File as Input for ancIBD\n",
    "\n",
    "This Vignette Notebook runs you through the steps for producing the input that ancIBD needs, a so called hdf5 file. We chose this file format for its ability to store meta data in a folder-like internal structure, and ability for partial reading the data (for details of this file format, see https://en.wikipedia.org/wiki/Hierarchical_Data_Format)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Point: A imputed and phased VCF\n",
    "Generallz, an `ancIBD` pipeline starts from an externally imputed and phased VCF. `ancIBD` is optimized to work with data that is output from `GLIMPSE` (see https://odelaneau.github.io/GLIMPSE/ for documentation and examples) when using the publicly available 1000G reference haplotype panel.\n",
    "\n",
    "### Transforming VCF to HDF5 Files\n",
    "The notebook here showcases how to produce a HDF5 file from the Glimpse output VCF.\n",
    "\n",
    "### Requirements of input VCF:\n",
    "Importantly, the input for `ancIBD` should have two fields:\n",
    "- GT: Diploid Genotype (the most likely imputed phased diploid genotype)\n",
    "- GP: Genotype probabilities\n",
    "\n",
    "These two fields are in the standard VCF output of Glimpse. They get then transformed to the HDF5 file, and these data is key for a successful run of `ancIBD`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/n/groups/reich/hringbauer/git/hapBLOCK/notebook/vignette\n"
     ]
    }
   ],
   "source": [
    "### First do Python Imports and set working directory\n",
    "import sys as sys\n",
    "import os\n",
    "import matplotlib.cm as cm\n",
    "import pandas as pd\n",
    "\n",
    "###\n",
    "# Edit the following path to your vignette folder:\n",
    "path = \"/n/groups/reich/hringbauer/git/hapBLOCK/notebook/vignette/\"\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd())\n",
    "###\n",
    "\n",
    "### The following Code sets the working directory to your ancIBD code \n",
    "### Please comment out and set path if you want to use custom ancIBD versions\n",
    "sys.path.insert(0,\"/n/groups/reich/hringbauer/git/hapBLOCK/package/\")  # Set path to custom ancIBD package first in path\n",
    "\n",
    "from ancIBD.IO.prepare_h5 import vcf_to_1240K_hdf  # The ancIBD helper function that converst VCF to HDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Transform HDF5 to VCF\n",
    "The funcion `vcf_to_1240k_hdf` runs the transformation from VCF and outputs a hdf5 for 1240k SNPs.\n",
    "\n",
    "### Input and Output:\n",
    "Generally, input data for ancIBD is organized per chromosomes - with one file for each chromosome.\n",
    "\n",
    "### Parameters\n",
    "One needs to set paths for the intermediate files:\n",
    "- path_vcf: Path of an intermediate VCF file - which is internally filtered to 1240k data \n",
    "- path_h5: Path of the output HDF5 files\n",
    "- marker_path: Path of the 1240k SNPs to use (a simple table provided with the example data)\n",
    "- map_path: Path of the map file to use (eigenstrat .snp provided with the example data, it has the map data included)\n",
    "- af_path (optional): Path of allele frequencies to merge into hdf5 file\n",
    "The data for the 1240k SNPs (`marker_path`), for the linkage map (`map_path`) and allele frequencies (`af_path`) are provided with the vignette, and only needs to be changed for custom SNP sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to create H5 from VCF\n",
    "Below you find the function call for a single chromosome. You can write a loop (see below), or also use an array job to run this function on a cluster. The latter will save a lot of runtime on big input data as it runs in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print downsampling to 1240K...\n",
      "Running bash command: \n",
      "bcftools view -Oz -o ./data/vcf.1240k/example_hazelton_chr22.vcf.gz -T ./data/filters/snps_bcftools_ch22.csv -M2 -v snps ./data/vcf.raw/example_hazelton_chr22.vcf.gz\n",
      "Finished BCF tools filtering to target markers.\n",
      "Deleting previous HDF5 file at path_h5: ./data/hdf5/example_hazelton_chr22.h5...\n",
      "Converting to HDF5...\n",
      "Finished conversion to hdf5!\n",
      "Merging in LD Map..\n",
      "Lifting LD Map from eigenstrat to HDF5...\n",
      "Loaded 15483 variants.\n",
      "Loaded 6 individuals.\n",
      "Loaded 16420 Chr.22 1240K SNPs.\n",
      "Intersection 15408 out of 15483 HDF5 SNPs\n",
      "Interpolating 75 variants.\n",
      "Finished Chromosome 22.\n",
      "Adding map to HDF5...\n",
      "Intersection 15408 out of 15483 target HDF5 SNPs. 75 SNPs set to AF=0.5\n",
      "Transformation complete! Find new hdf5 file at: ./data/hdf5/example_hazelton_chr22.h5\n",
      "\n",
      "CPU times: user 9.84 s, sys: 605 ms, total: 10.4 s\n",
      "Wall time: 13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ch = 22\n",
    "\n",
    "base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "vcf_to_1240K_hdf(in_vcf_path = f\"./data/vcf.raw/example_hazelton_chr{ch}.vcf.gz\",\n",
    "                 path_vcf = f\"./data/vcf.1240k/example_hazelton_chr{ch}.vcf.gz\",\n",
    "                 path_h5 = f\"./data/hdf5/example_hazelton_chr{ch}.h5\",\n",
    "                 marker_path = f\"./data/filters/snps_bcftools_ch{ch}.csv\",\n",
    "                 map_path = f\"./data/v51.1_1240k.snp\", \n",
    "                 af_path = f\"./data/afs/v51.1_1240k_AF_ch{ch}.tsv\",\n",
    "                 col_sample_af = \"\", \n",
    "                 buffer_size=20000, chunk_width=8, chunk_length=20000,\n",
    "                 ch=ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Glimpse vcf -> hdf5 over all chromosomes\n",
    "This is the same as the run for a single chromsome above, but now looped over multiple chromsomes.\n",
    "\n",
    "The runtime can go into the minutes or even hours for larger datasets. Parallelization of this transformation (e.g. via a parralel array job on a cluster, running each chromosome in parallel) can speed up that time if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "chs = range(1,23)\n",
    "\n",
    "for ch in chs:\n",
    "    base_path = f\"/n/groups/reich/hringbauer/git/hapBLOCK\"\n",
    "    vcf_to_1240K_hdf(in_vcf_path = f\"./data/vcf.raw/example_hazelton_chr{ch}.vcf.gz\",\n",
    "                     path_vcf = f\"./data/vcf.1240k/example_hazelton_chr{ch}.vcf.gz\",\n",
    "                     path_h5 = f\"./data/hdf5/example_hazelton_chr{ch}.h5\",\n",
    "                     marker_path = f\"./data/filters/snps_bcftools_ch{ch}.csv\",\n",
    "                     map_path = f\"./data/v51.1_1240k.snp\", \n",
    "                     af_path = f\"./data/afs/v51.1_1240k_AF_ch{ch}.tsv\",\n",
    "                     col_sample_af = \"\", \n",
    "                     buffer_size=20000, chunk_width=8, chunk_length=20000,\n",
    "                     ch=ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "Congratulations, this is it! You just have created the output data needed for `ancIBD`. Now you can continue with the actual `ancIBD` run in the vignette notebook in `./run_ancIBD.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

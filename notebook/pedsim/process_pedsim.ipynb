{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/ped-sim\n",
      "CPU Count: 28\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os as os\n",
    "import sys as sys\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py as h5py\n",
    "from scipy import interpolate\n",
    "\n",
    "### Do the Arial \n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'   # Set the default\n",
    "rcParams['font.sans-serif'] = ['Arial']  # Make sure to have the font installed (it is on cluster for Harald)\n",
    "\n",
    "### Pick the right path (whether on cluster or at home)\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "if socket_name == \"VioletQueen\":\n",
    "    path = \"/home/harald/git/HAPSBURG/\"   # The Path on Harald's machine\n",
    "elif socket_name.startswith(\"midway2\"):\n",
    "    print(\"Midway jnovmbre partition detected.\")\n",
    "    path = \"/project2/jnovembre/hringbauer/ped-sim/\"  # The Path on Midway Cluster\n",
    "elif socket_name.startswith(\"Harald-Laptop\"):\n",
    "    print(\"Harald's new laptop detected!\")\n",
    "    path = \"/home/hringbauer/git/ped-sim/\" \n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/ped-sim/\"  # The Path on Midway Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "    \n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "\n",
    "sys.path.append(\"./package/\")  # Go to the hapsburg package directory\n",
    "\n",
    "from hapsburg.PackagesSupport.pp_individual_roh_csvs import post_process_roh_df, combine_ROH_df, calc_average_roh\n",
    "from hapsburg.figures.plot_bars import plot_panel_row, prepare_dfs_plot, create_cousins_roh\n",
    "\n",
    "#sys.path.insert(0,\"/n/groups/reich/hringbauer/git/hapBLOCK/package/\")  # hack to get development package first in path\n",
    "from ancIBD.IO.ind_ibd import create_ind_ibd_df\n",
    "\n",
    "print(os.getcwd()) # Show the current working directory. Should be HAPSBURG/Notebooks/ParallelRuns\n",
    "print(f\"CPU Count: {mp.cpu_count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segment_file(path_segments=\"../ped-sim/output/output.seg\",\n",
    "                      cm_fac=0.01):\n",
    "    \"\"\"Load and return segment File of IBD & ROH blocks.\n",
    "    Return Pandas dataframe. \n",
    "    cm_fac: Factor with which to multiply genetic length columns\"\"\"\n",
    "    df = pd.read_csv(path_segments, sep=\"\\t\", header=None)\n",
    "    df.columns = [\"iid1\", \"iid2\", \"ch\", \"Start\", \"End\", \n",
    "                  \"ibd_stat\", \"StartM\", \"EndM\", \"lengthM\"]\n",
    "    df[\"length\"] = (df[\"End\"] - df[\"Start\"])\n",
    "    \n",
    "    for col in [\"StartM\", \"EndM\", \"lengthM\"]:\n",
    "        df[col] = df[col] * cm_fac\n",
    "    return df\n",
    "\n",
    "def to_hapsburg_ibd_df(path_segments = \"../ped-sim/output/test.seg\",\n",
    "                   savepath = \"\", n=500, merge=False,\n",
    "                   h5_path = \"\",\n",
    "                   min_cm=[8, 12, 16, 20], snp_cm=220,\n",
    "                   gap=0.5, min_len1=2, min_len2=4,\n",
    "                   output=False, sort=True):\n",
    "    \"\"\"Load pd_sim output and post_process into Hapsburg\n",
    "    Summary output. Return this dataframe.\n",
    "    If savepath is given, save to there (tab-seperated)\"\"\"\n",
    "    df1 = load_segment_file(path_segments)  # Load the full segment file, transfomred\n",
    "    \n",
    "    if merge:\n",
    "        df1 = merge_called_blocks(df1, output=True)\n",
    "        \n",
    "    ### Pre-Process if h5 given\n",
    "    if len(h5_path)>0:\n",
    "        df1 = cap_ibd_boarders(df1, h5_path=h5_path)\n",
    "        df1 = transform_to_snp_pos(df1, h5_path=h5_path)\n",
    "        \n",
    "    df_ibd = create_ind_ibd_df(ibd_data=df1,\n",
    "                  min_cms=min_cm, snp_cm=snp_cm, min_cm=4,\n",
    "                  sort_col=-1, savepath=savepath,\n",
    "                  output=False)\n",
    "    \n",
    "    #assert(len(df_ibd)==n) # Sanity Check    \n",
    "    return df_ibd\n",
    "\n",
    "def merge_called_blocks(df, output=False):\n",
    "        \"\"\"Merge Blocks in Dataframe df and return merged Dataframe.\n",
    "        Gap is given in Morgan\"\"\"\n",
    "        if len(df) == 0:\n",
    "            return df  # In case of empty dataframe don't do anything\n",
    "\n",
    "        df_n = df.drop(df.index)  # Create New Data frame with all raws removed\n",
    "        row_c = df.iloc[0, :].copy()\n",
    "        #row_c[\"lengthM\"] = row_c[\"EndM\"] - row_c[\"StartM\"] # Should be there\n",
    "\n",
    "        # Iterate over all further rows, update blocks if gaps small enough\n",
    "        for index, row in df.iloc[1:,:].iterrows():\n",
    "            ### Calculate Conditions\n",
    "            con1 = (row[\"Start\"] == row_c[\"End\"]+1)\n",
    "            con2 = row[\"ch\"] == row_c[\"ch\"]\n",
    "            con3 = row[\"iid1\"] == row_c[\"iid1\"]\n",
    "            con4 = row[\"iid2\"] == row_c[\"iid2\"]\n",
    "            \n",
    "            if con1 & con2 & con3 & con4:\n",
    "                row_c[\"End\"] = row[\"End\"]\n",
    "                row_c[\"EndM\"] = row[\"EndM\"]\n",
    "                row_c[\"length\"] = row_c[\"End\"] - row_c[\"Start\"]\n",
    "                row_c[\"lengthM\"] = row_c[\"EndM\"] - row_c[\"StartM\"]\n",
    "\n",
    "            else:  # Save and go to next row\n",
    "                df_n.loc[len(df_n)] = row_c  # Append a row to new df\n",
    "                row_c = row.copy()\n",
    "\n",
    "        df_n.loc[len(df_n)] = row_c   # Append the last row\n",
    "\n",
    "        if output == True:\n",
    "            print(f\"Merged n={len(df) - len(df_n)} gaps\")\n",
    "        return df_n\n",
    "    \n",
    "##############################\n",
    "### Adapt to SNPs in h5\n",
    "\n",
    "def cap_ibd_boarders(df, chs = range(1,23), \n",
    "                     h5_path = \"/n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v54.1/ch\"):\n",
    "    \"\"\"Cuts IBD segment file for ch in chs to boundaries matching h5 in h5_path\"\"\"\n",
    "    \n",
    "    for ch in chs:\n",
    "        with h5py.File(f\"{h5_path}{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "            min_map, max_map =  f[\"variants/MAP\"][0],f[\"variants/MAP\"][-1]\n",
    "\n",
    "        idx_ch = df[\"ch\"]==ch ## Find all segments on chromosome\n",
    "\n",
    "        ### Cut to Start Positions\n",
    "        idx = df[\"StartM\"]<min_map\n",
    "        df[idx_ch & idx] = min_map\n",
    "        idx = df[\"EndM\"]<min_map\n",
    "        df[idx_ch & idx] = min_map\n",
    "\n",
    "        ### Cut to End Positions\n",
    "        idx = df[\"StartM\"]>max_map\n",
    "        df[idx_ch & idx] = max_map\n",
    "        idx = df[\"EndM\"]>max_map\n",
    "        df[idx_ch & idx] = max_map\n",
    "\n",
    "    df[\"LengthM\"]= df[\"EndM\"]-df[\"StartM\"] # Update IBD Length\n",
    "    # Remove IBD segments fuly out of boarder\n",
    "    idx = df[\"LengthM\"]==0\n",
    "    df = df[~idx].copy().reset_index(drop=True) \n",
    "    return df\n",
    "\n",
    "def transform_to_snp_pos(df, chs=range(1,23), \n",
    "                         h5_path = \"/n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v54.1/ch\"):\n",
    "    \"\"\"Transform positions in IBD dataframe to positions matching indices in 1240k file\"\"\"\n",
    "    \n",
    "    for ch in chs:\n",
    "        with h5py.File(f\"{h5_path}{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "                m = f[\"variants/MAP\"][:]\n",
    "        p = np.arange(len(m))\n",
    "        f = interpolate.interp1d(m, p)\n",
    "        \n",
    "        ### Map to approximate index positions\n",
    "        idx_ch = df[\"ch\"]==ch ## Find all segments on chromosome\n",
    "        df.loc[idx_ch, \"Start\"] = f(df[\"StartM\"][idx_ch]) \n",
    "        df.loc[idx_ch, \"End\"] = f(df[\"EndM\"][idx_ch])\n",
    "    df[\"length\"] = df[\"End\"] - df[\"Start\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to hapBLOCK format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = load_segment_file(path_segments = \"./output/ibd/sib.seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1[df1[\"iid1\"].str.contains(\"sib1_g2-b1-i1\")][:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.46297627"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dft = df1[df1[\"iid1\"].str.contains(\"gp11_g1\")]\n",
    "\n",
    "np.sum(dft[\"lengthM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = \"/n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av2.tsv\n",
      "CPU times: user 379 ms, sys: 2.92 ms, total: 382 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av2 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av2.seg\", \n",
    "                     n=100, savepath=out_folder+\"av2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av1.tsv\n",
      "CPU times: user 382 ms, sys: 1.97 ms, total: 384 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av1 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av1.seg\", \n",
    "                     n=100, savepath=out_folder+\"av1.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av2.tsv\n",
      "CPU times: user 381 ms, sys: 8.05 ms, total: 389 ms\n",
      "Wall time: 389 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av3 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av2.seg\", \n",
    "                     n=100, savepath=out_folder+\"av2.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av3.tsv\n",
      "CPU times: user 402 ms, sys: 1.92 ms, total: 404 ms\n",
      "Wall time: 407 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av5 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av3.seg\", \n",
    "                     n=100, savepath=out_folder+\"av3.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av4.tsv\n",
      "CPU times: user 397 ms, sys: 1.98 ms, total: 399 ms\n",
      "Wall time: 403 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av5 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av4.seg\", \n",
    "                     n=100, savepath=out_folder+\"av4.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av5.tsv\n",
      "CPU times: user 382 ms, sys: 5.96 ms, total: 388 ms\n",
      "Wall time: 397 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_av5 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/av5.seg\", \n",
    "                     n=100, savepath=out_folder+\"av5.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grand Parental Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 400 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/parent.tsv\n",
      "CPU times: user 1.3 s, sys: 9.96 ms, total: 1.31 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_gp0 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/parent.seg\", \n",
    "                            n=100, savepath=out_folder+\"parent.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gp0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/gp1.tsv\n",
      "CPU times: user 698 ms, sys: 3.97 ms, total: 702 ms\n",
      "Wall time: 712 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_gp1 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/gp1.seg\", \n",
    "                     clst=\"gp1\", n=100,\n",
    "                     savepath=out_folder+\"gp1.tsv\")\n",
    "df_gp1 = df_gp1[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_gp2 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/gp2.seg\", n=100,\n",
    "                     savepath=out_folder+\"gp2.tsv\") #out_folder+\"gp2.tsv\"\n",
    "#df_gp2 = df_gp2[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/gp3.tsv\n",
      "CPU times: user 694 ms, sys: 3.99 ms, total: 698 ms\n",
      "Wall time: 706 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_gp3 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/gp3.seg\", \n",
    "                     clst=\"gp3\", n=100,\n",
    "                     savepath=out_folder+\"gp3.tsv\")\n",
    "df_gp3 = df_gp3[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged n=6646 gaps\n",
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/sib.tsv\n",
      "CPU times: user 28.7 s, sys: 32.1 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_sib = to_hapsburg_ibd_df(path_segments = \"./output/ibd/sib.seg\", \n",
    "                     n=100, savepath=out_folder+\"sib.tsv\", merge=True) ### Merging is activated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/hsib.tsv\n",
      "CPU times: user 378 ms, sys: 5.04 ms, total: 384 ms\n",
      "Wall time: 394 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_hsib = to_hapsburg_ibd_df(path_segments = \"./output/ibd/hsib.seg\", \n",
    "                     clst=\"hsib\", n=100,\n",
    "                     savepath=out_folder+\"hsib.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Pre-Process with H5 Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5_path = \"/n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v54.1/ch\"\n",
    "out_folder = \"/n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av1.f.tsv\n",
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av2.f.tsv\n",
      "Saved 100 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av3.f.tsv\n",
      "Saved 99 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av4.f.tsv\n",
      "Saved 99 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/av5.f.tsv\n",
      "CPU times: user 4.52 s, sys: 160 ms, total: 4.68 s\n",
      "Wall time: 5.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1,6):\n",
    "    p = \"av\" + str(i)\n",
    "    dft = to_hapsburg_ibd_df(path_segments = f\"./output/ibd/{p}.seg\", \n",
    "                             h5_path=h5_path, savepath=out_folder+f\"{p}.f.tsv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 200 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/gp1.f.tsv\n",
      "Saved 200 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/gp2.f.tsv\n",
      "Saved 200 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/gp3.f.tsv\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,4):\n",
    "    p = \"gp\" + str(i)\n",
    "    dft = to_hapsburg_ibd_df(path_segments = f\"./output/ibd/{p}.seg\", \n",
    "                     h5_path=h5_path,\n",
    "                     savepath=out_folder+f\"{p}.f.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 400 individual IBD pairs to: /n/groups/reich/hringbauer/git/hapBLOCK/output/pedsim/parent.f.tsv\n",
      "CPU times: user 1.97 s, sys: 53 ms, total: 2.03 s\n",
      "Wall time: 2.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_gp0 = to_hapsburg_ibd_df(path_segments = \"./output/ibd/parent.seg\", \n",
    "                            n=100, h5_path=h5_path, savepath=out_folder+\"parent.f.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "df_sib = to_hapsburg_ibd_df(path_segments = \"./output/ibd/sib.seg\", \n",
    "                     h5_path=h5_path, savepath=out_folder+\"sib.f.tsv\", merge=True) ### Merging is activated here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_hsib = to_hapsburg_ibd_df(path_segments = \"./output/ibd/hsib.seg\", \n",
    "                             h5_path=h5_path, savepath=out_folder+\"hsib.f.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Area 51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cutting to ancIBD SNPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = load_segment_file(path_segments = \"./output/ibd/sib.seg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h5_path = \"/n/groups/reich/hringbauer/git/hapBLOCK/data/hdf5/1240k_v54.1/ch\"\n",
    "ch =1\n",
    "\n",
    "with h5py.File(f\"{h5_path}{ch}.h5\", \"r\") as f: # Load for Sanity Check. See below!\n",
    "    m = f[\"variants/MAP\"][:]\n",
    "    \n",
    "min_map, max_map = m[0], m[-1]\n",
    "p = np.arange(len(m)) # 1240k SNP positions index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### First: Cut IBD \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11638\n",
      "10156\n"
     ]
    }
   ],
   "source": [
    "df1 = load_segment_file(path_segments = \"./output/ibd/sib.seg\")\n",
    "print(len(df1))\n",
    "df1 = cap_ibd_boarders(df1)\n",
    "print(len(df1))\n",
    "df1 = transform_to_snp_pos(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = interpolate.interp1d(m, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(88407.)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f(max_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 88405, 88406, 88407])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

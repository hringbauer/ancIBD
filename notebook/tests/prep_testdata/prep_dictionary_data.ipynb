{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d49f8b6-a1c5-4101-8996-53d92df56a30",
   "metadata": {},
   "source": [
    "# Prepare Test Data for Dictionary Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f0dcd3c-a871-4482-b2a2-e3d39fc6834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compute-e-16-233.o2.rc.hms.harvard.edu\n",
      "HSM O2 Computational partition detected.\n",
      "/n/groups/reich/hringbauer/git/hapBLOCK\n"
     ]
    }
   ],
   "source": [
    "import socket as socket\n",
    "import os as os\n",
    "import sys as sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import  pandas as pd\n",
    "import h5py\n",
    "import pickle\n",
    "\n",
    "socket_name = socket.gethostname()\n",
    "print(socket_name)\n",
    "\n",
    "if socket_name.startswith(\"compute-\"):\n",
    "    print(\"HSM O2 Computational partition detected.\")\n",
    "    path = \"/n/groups/reich/hringbauer/git/hapBLOCK/\"  # The Path on Harvard Cluster\n",
    "else: \n",
    "    raise RuntimeWarning(\"Not compatible machine. Check!!\")\n",
    "\n",
    "os.chdir(path)  # Set the right Path (in line with Atom default)\n",
    "print(os.getcwd())\n",
    "\n",
    "### The following Code sets the working directory to your ancIBD code\n",
    "# If using system ancIBD installation comment out:\n",
    "#sys.path.insert(0,\"/n/groups/reich/hringbauer/git/hapBLOCK/package/\")  # hack to get development package first in path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3d46ce-0afb-4fae-b9c1-87634b3f07c9",
   "metadata": {},
   "source": [
    "# Load HDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c233ef01-fcc5-4eaf-adab-fe561fa68142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69063, 29162, 2)\n",
      "['AF', 'AF_SAMPLE', 'ALT', 'BUF', 'CHROM', 'FILTER_PASS', 'ID', 'INFO', 'MAP', 'POS', 'QUAL', 'RAF', 'REF', 'altlen', 'is_snp', 'numalt']\n"
     ]
    }
   ],
   "source": [
    "path_h5 = \"./data/hdf5/1240k_v56.3/ch5.h5\"\n",
    "\n",
    "iids = [\"I12439\", \"I12440\"]\n",
    "iid1, iid2 = iids[0], iids[1]\n",
    "with h5py.File(path_h5, \"r\") as f:\n",
    "    #print(list(f[\"calldata\"]))\n",
    "    ### Extract Data relevant to two samples\n",
    "    # Extract Sample Indices\n",
    "    samples = f[\"samples\"][:].astype(\"str\")\n",
    "    i1 = np.where(samples==iid1)[0][0] # Sample 1\n",
    "    i2 = np.where(samples==iid2)[0][0] # Sample 2\n",
    "\n",
    "    print(np.shape(f[\"calldata/GT\"]))\n",
    "    g1 = f[\"calldata/GT\"][:, i1,:]\n",
    "    g2 = f[\"calldata/GT\"][:, i2,:]\n",
    "\n",
    "    gp1 =  f[\"calldata/GP\"][:, i1,:]\n",
    "    gp2 =  f[\"calldata/GP\"][:, i2,:]\n",
    "\n",
    "    ### Get overall statistics of genome region\n",
    "    print(list(f[\"variants\"]))\n",
    "    af = f[\"variants/RAF\"][:]\n",
    "    pos = f[\"variants/POS\"][:]\n",
    "    gmap = f[\"variants/MAP\"][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fed42b4-3be9-4b9f-b581-5a0f367f9904",
   "metadata": {},
   "source": [
    "### Create Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dcb57cc8-d4ab-4579-bec2-1509e9ffacc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dct = {\n",
    "    'calldata/GT':np.stack((g1,g2), axis=1),\n",
    "    'calldata/GP':np.stack((gp1,gp2), axis=1),\n",
    "    'calldata/AF': af,\n",
    "    'variants/POS':pos,\n",
    "    'variants/MAP':gmap,\n",
    "    'samples':np.array(iids)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d1cbe7-35d1-4031-991b-967461b5ca75",
   "metadata": {},
   "source": [
    "### Pickle the input dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3de58237-1a67-429b-887c-5049bb5f9776",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = \"./output/dumpster/unittests/dict_I12439-I12440_chr5.pickle\"\n",
    "\n",
    "with open(savepath, 'wb') as handle:\n",
    "    pickle.dump(save_dct, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb59b252-a59c-46d4-b2f9-af61108a35f7",
   "metadata": {},
   "source": [
    "# Area 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b5eb4b-527f-48cc-bec9-7019583eb972",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "a = {'hello': 'world'}\n",
    "\n",
    "with open('filename.pickle', 'wb') as handle:\n",
    "    pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('filename.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "\n",
    "print(a == b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
